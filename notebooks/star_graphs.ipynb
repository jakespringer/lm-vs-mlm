{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarGraph:\n",
    "    def __init__(self, center, branches, goal_branch=None, randomize_edge_list=True):\n",
    "        self.center = center\n",
    "        self.branches = branches\n",
    "        self.start = center if goal_branch is not None else None\n",
    "        self.goal = branches[goal_branch][-1] if goal_branch is not None else None\n",
    "        self.edge_list_indices = np.arange(len(branches)*len(branches)+1)\n",
    "        self.goal_branch = goal_branch\n",
    "\n",
    "    def get_edge_list(self):\n",
    "        edge_list = []\n",
    "        for branch in self.branches:\n",
    "            edge_list.append((self.center, branch[0]))\n",
    "            edge_list.extend([(branch[i-1], branch[i]) for i in range(1, len(branch))])            \n",
    "        return edge_list\n",
    "\n",
    "    @staticmethod\n",
    "    def random_graph(n, m, N=None):\n",
    "        if N is None:\n",
    "            graph_indices = np.random.permutation(n*m+1)\n",
    "        else:\n",
    "            graph_indices = np.random.choice(N, n*m+1, replace=False)\n",
    "        center = graph_indices[0]\n",
    "        branches = [graph_indices[i*m+1:(i+1)*m+1] for i in range(n)]\n",
    "        return StarGraph(center, branches, np.random.randint(n))\n",
    "\n",
    "    @staticmethod\n",
    "    def random_graphs(n_param, m_param, k, N=None, dist='constant'):\n",
    "        if dist == 'uniform':\n",
    "            ns = np.random.randint(n_param[0], n_param[1], k)\n",
    "            ms = np.random.randint(m_param[0], m_param[1], k)\n",
    "            return [StarGraph.random_graph(n, m, N=N) for n, m in zip(ns, ms)]\n",
    "        elif dist == 'normal':\n",
    "            ns = np.random.normal(n_param[0], n_param[1], k).astype(int)\n",
    "            ms = np.random.normal(m_param[0], m_param[1], k).astype(int)\n",
    "            return [StarGraph.random_graph(n, m, N=N) for n, m in zip(ns, ms)]\n",
    "        elif dist == 'constant':\n",
    "            return [StarGraph.random_graph(n_param, m_param, N=N) for _ in range(k)]\n",
    "        else:\n",
    "            raise ValueError('Invalid distribution type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StarGraphTokenizer:\n",
    "    def __init__(self, N):\n",
    "        self.N = N\n",
    "        self.edge_delim = self.N\n",
    "        self.goal_delim = self.N + 1\n",
    "        self.equals = self.N + 2\n",
    "        self.end_of_string = self.N + 3\n",
    "        self.pad = self.N + 4\n",
    "\n",
    "    def tokenize(self, graphs, with_solution=False, padding=True, max_length=None, return_tensors='torch'):\n",
    "        if max_length is not None:\n",
    "            raise NotImplementedError('max_length not yet implemented')\n",
    "        if isinstance(graphs, StarGraph):\n",
    "            graphs = [graphs]\n",
    "        tokens = []\n",
    "        attention_mask = []\n",
    "        for graph in graphs:\n",
    "            graph_tokens = self._tokenize_graph(graph, with_solution=with_solution)\n",
    "            tokens.append(graph_tokens)\n",
    "            attention_mask.append([1]*len(graph_tokens))\n",
    "        if padding:\n",
    "            max_length = max([len(token) for token in tokens])\n",
    "            for token in tokens:\n",
    "                token.extend([self.pad] * (max_length - len(token)))\n",
    "            for target_id in attention_mask:\n",
    "                target_id.extend([0] * (max_length - len(target_id)))\n",
    "        if return_tensors == 'torch':\n",
    "            tokens = torch.tensor(tokens)\n",
    "            attention_mask = torch.tensor(attention_mask)\n",
    "        elif return_tensors == 'np':\n",
    "            tokens = np.array(tokens)\n",
    "            attention_mask = np.array(attention_mask)\n",
    "        else:\n",
    "            raise ValueError('Invalid return_tensors')\n",
    "        return {\n",
    "            'input_ids': tokens,\n",
    "            'attention_mask': attention_mask\n",
    "        }\n",
    "    \n",
    "    def _tokenize_graph(self, graph, with_solution=False):\n",
    "        tokens = [self.edge_delim]\n",
    "        edge_list = graph.get_edge_list()\n",
    "        for edge in edge_list:\n",
    "            tokens.extend([edge[0], edge[1], self.edge_delim])\n",
    "        tokens.extend([self.goal_delim, graph.start, graph.goal, self.equals])\n",
    "        if with_solution:\n",
    "            tokens.append(graph.center)\n",
    "            tokens.extend(graph.branches[graph.goal_branch])\n",
    "            tokens.append(self.end_of_string)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "tokenizer = StarGraphTokenizer(N)\n",
    "graphs = StarGraph.random_graphs(3, 3, 100, N=N, dist='constant')\n",
    "tokens = tokenizer.tokenize(graphs, with_solution=True, padding=True, return_tensors='pt')\n",
    "tokens_wo_solution = tokenizer.tokenize(graphs, with_solution=False, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[100,  12,  84,  ...,  92,  30, 103],\n",
       "         [100,  70,  89,  ...,  35,  62, 103],\n",
       "         [100,  72,  28,  ...,  22,   0, 103],\n",
       "         ...,\n",
       "         [100,  28,  88,  ...,   7,   4, 103],\n",
       "         [100,  94,  51,  ...,  62,  39, 103],\n",
       "         [100,  29,  14,  ...,  13,  48, 103]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1]])}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
